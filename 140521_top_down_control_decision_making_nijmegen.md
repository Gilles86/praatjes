# Dialogues on the role of top-down factors in sensory processing

Very abstract pattern of patches, when "famous trilogy" is mentioned, you
seen Darth Vader.

Two possible mechanisms:
 1. Series of features that recall memory
 2. Top-down modulation of attention to features that might code for Darth
    Vader

Two themes today:
1. Are expectation and attention the same or different?
2. Does the human brain implement predictive coding?
3. What is the "top" in top-down?

# Are expectation and attention the same or different?

## Chris Summerfield - Expectation and attention: dissociable influences on visual cognition?
Expectation can mean many different things in different contexts

1. Statistical learning
2. Predictive coding/gestalt/context
3. Sensory precueing
4. Priming/repetition

For attention, the same thing:
1. Arousal/alertness
2. Control (resources)
3. Spatial/selective/temporal orientation, feature-based...

Example of importance of context: when driving through Scotland, one
expects highland cows, but not palm trees.

This context will have to influence the internal representation of some
concepts: top-down processes.

Misperception is not just accompanied by pushing the wrong button/saying a
word, but also in differential activity in sensory regions.

Summerfield et al, 2006 (Cerebral Cortex): misreported houses have similar
activity as (well-reported) faces in fusiform face area (FFA).

Egner et al. (2010, JoN): Under passive viewing, FFA activated by houses
when face expectation is high (BOLD patterns between faces and houses are
more similar when they are more expected).

Explanation: expected inputs are "explained away".

This would suggest that there are two different neural units: 'E' and
'R'-units.

de Gardelle et al (2013): repeated streams of faces.
MVPA approach made it possible to distinguish voxels that (1) respond positively
or (2) respond negatively to repetition. Corresponding to respectively R
and E units.

### Expectation/attention 
When you're driving through Scotland you're not paying attention to
expected Highlander cows. However, you are paying attention to expected
traffic signs.
Two dimensions:
1. Expected
2. Relevance

Experimental paradigms often confound signal expectancy with signal
relevance.

"People introducing their talks on attention, often start their talks with
examples where expected locations/features are 'boosted'"

How do attention and expectation interact?
Rao & ... (2005): expected feastures are boosted using 'gating matrix',
not-expected features are filtered away.

Eckstein; Yu & Dayan (2004): Bayesian model of attention - distinguish
signal from noise using a prior.

These Bayesian models are different from 'contrast gain models', that model
attention as a neural gain mechanism.

Study where participants had to search for male faces or female faces.
Question was whether expectancy or attention would modulate decoding
accuracy. When attended, faces or houses can be decoded from FFA/PPA.
Expectancy did not modulate the classification accuracy.

### Conclusion
Expectation does two things:
Expectations make observers more senstivive to predicted information
Shapes perception
?

### Questions
Important distinction: endogeneous versus external information.

Important itneraction between attention and expectancy is that we turn our
attention to unexpected features. In most experiments these two things are
decoupled.

## Sid Kouider - How expectations shape perception: new isnights from infants and subliminal priming
Research is on development of consciousness in childeren, as well as
consciousness in adults. Which tasks need to be performed in consciousness?

Dynamics of consciousness: two stages with distinct signatures
 1. First ~ 200 - 300ms, brain responses increase linearly with stimulus
    energy/duration.
    This even occurs for stimuli that stay subjectively invisible.
 2. Second stage reflect non-linear, all-or-none changes coinciding with
    subjective reports. This happens in later areas.
    - These also feedback into earlier visual areas.

Traditionally, babies were considered not to have consciousness. They were
even operated on without anesthesia.

Kouder et al (2013, Science): masked face is flashed for a variable
duration to babies. Also babies (~11 months old) show an
all-or-none-ignition for longer showed faces as opposed to shorter showed
faces.

Anticipatory eye movement is a common tool for testing infant capabilities

Follow-up: 75% valid / 25% invalid sound cues, predicting face/flowers,
showed 66-133ms (masked by two pictures of a rock).

EEG on occipital/parietal areas shows modulation by predictive cues, but
only after 1000ms or so. Early EEG signal, representing early visual
processing is not modulated by predictive cues.

### Repetition priming, priors and awareness 
Predictive coding models assume that repetition suppression reflects
attenuated surprise for repeated stimulus.

Repetition supressing id modulated by repetition probabilities (Summerfield
& Egner, 2008).

Limits to repetition suppression:
1. Independent from task-related attion, its modulation by expectations
   requires attention.
2. It occurs for any object, bu it modulation by expectations is restricted
   to stimuli with high expertise (faces, letters, ...)

Task: determine orientation of Gabor patches. They are primed either
subliminal or consciously by other Gabor patches, very shortly just before
the. Even subliminal primes can modulate target response, but only when the
Gabor patches were predictive in 80% of the trials.

### Questions
Floris: baby paradigm with predictive cues - what would happen in adults?

## Discussion
"What is in our awareness?"
Sid: stimuli you are looking for will induce aware representationsm as well
as unexpected stimuli.


Sid: predictive coding happens at a (anatomically) local way: feedback
loops within regions or regions that are close together. It is not all
prefrontal cortex.

Chris: not expert of consciousness, but "willing to accept" the theory that
awareness/consciousness is "qualitatively non-linear phenomenon", where
information enters the boundary of consciousness.

Prefrontal cortex codes represents information that is relevant to decision
making at longer temporal scales.

Model of world in mind that makes predictions can be influenced by mood?
Example, Chris: stimulus that can be manipulated by single parameter that
makes it look more or less as water. Subjects that were made thirsty due to
salty crisps and no water reported less-water-like stimuli more as water
than subjects that were not thirsty.

#### Back to attention versus predictive coding

Chris: Karl Friston gave nice normative, Bayesian model of how we should
make decisions and use priors, etc.  Results from behavioral ecology have
had a large impact in value-base decision making: we have limited cognitive
resources, so we cannot infer over all possible outcomes. So, in this
regime of limited resources, it's necessary to tune the neural
representations in such a way that they maximize the amount of information
they can carry.  Example: your value system can not represent the value of
a laptop and the value of an apple in the same way.
In perceptual decision making, we face a similar problem.
Example: when the door bell rings, we could infer over the possiblity that
Hillary Clinton would come through the door, but we don't have the
computational power to go over this possiblity and all other possibilities.
Therefore, we need a more efficient representation.


# Part 2: Does the human brain implement predictive coding?
## Jolien
Predictive coding has interested a broad area of fields in neuroscience,
information theory and even philosophy.

Karl Friston is a proponent of predictive coding and his own free energy
principle.

Pieter Roelfsema has explicitly argued against predictive coding.

## Karl Friston - Does the human brain implement predictive coding?

How far can we go with a normative theory that describes what 'the system'
has to compute for decision making/perception.

Many inspirations, Feynmann, von helmholtz, Bayes, Hinton...

"Especially interested in approximate, variational Bayes approachs"


### The anatomy of inference
#### Bayesian filtering and predictive coding
Function of (1) state of the world and (2) belief of the world. Two terms:
1. Predicton: based on what I see in the world an know, what do I expect
   next?
2. Update-term: how does what I see differ from what I expected.

Goal of Bayesian inference machine: mnimize prediction error.

Bayesian inference need generative model. To do this for the actual 'deep'
world, one needs a hierachial model.

Most simple implementation works with a hiearchy that has both 'ascending'
and 'descending' messages.

Two neural models:
1. Haeusler and Mass, Cereb Cortex, 2006
2. Bastos et al., Neuron, 2012

Saliency has only meaning in acting in the actual world.

Action regions are also part of the hiearchy. Many reflexes can be
interpreted as implementation of the network.

### Functional asymmetries
The non-linearity of the world we live in, has implications for the
frequency of message passing between Error and Expectation regions
(Superficial and Deep pyramidal cells).

"Spectral assymetry" of error and expectation cells, first formulated in
2008. Andre Bastos et al. have shown recently that such spectral
assymetries. Prime example of using normative theories for empirical
research.

The theory also predicts differences in e.g. NDMA receptor density. These
are found more in error cells. "Drivers" versus "modulators".

#### Conclusions
 * Hierachial predictive coding is plausible. Approximate Bayesian
   inference
 * Dual encoding of errors and expectation

### Action and perception
"Bayesian formulation of salience". Even in value-based decision making, in
the end you just minimize uncertainty.

If you build an engine that analytically minimizes uncertainty in this
Bayesian scheme, with as a task to recognize it starts making saccades that
look similar to those that people make when they do the same task.


## Pieter Roelfsema - How the visual brain construct objects from features

Example: group object on the foreground of very similar background.
Roelfsema: this is done by incremental segmentation.

Visual system of the macqauace, both regions and interconnections is mapped
out in very detailed way. Both feedforward and recurrent connections.

Even with only feedforward connections, a lot of visual processing can be
explained.

For boundary detection you need lateral inhibition.
For region filling you need lateral excitation.

How does the brain do this? Answer: feedback connections.

Macaques saw identical pictures. On some days they had to trace a line, on
other days they had to indicate a bounded region (indicated by changing
orientation).

///////////////
////\\\\\\\////
////\\\\\\\////
////\\\\\\\////
////\\\\\\\////
///////////////

In both conditions, retinotopically mapped neurons show activation based on
boundaries, but only in region indication condition, also neurons mapping
for regions within the boundary showed activation, as if region filling
only occurs when this is task relevant.

Multi-unit recording in different cortical layers shows that deeper layers
are activated before higher layers, as if they do boundary detection.

V1 and V4 can be microstimulated. Early V1 activation casuses increase of
V4 activation. Late V4 microstimulation causes increase even later in V1
activation.

### Conclusions
 * Boundary detection is an early, local process
 * Region filling 
 * ???

### Relation to predictive coding
Predictive Coding - Error Prediction -> inhibition of expected features
versus 
Adaptive Resonance - expected features are enhanced


## Discussion: Karl Friston versus Pieter Roelfsema
Jolien: Can what Pieter has just showed is counterevidence to predictive
coding?
Karl: No. It has to do with what you're modelling. Textures are
second-order statistics of the inputs, so it's different from what happens
in the space of inputs.

Roelfsema: I believe in Bayesian models, but what they predict: decrease of
activation of neural populations representing what is to be expected, is
'just not what we find'.

# What is the "top" in top-down?
Anke: earlier talks were about local interaction within adjacent brain
regions. Next talks are more about large interregional interactions.

Masha Bar is interested in modelling interactions between regions
throughtout the brain

Tobias Donner, effects of large-scale neuromodulation on decision making

## Mosha Bar
### Two problems
#### Boundary between perception and cognition
"The artificial boundary between perception and cognition": this is an
illusion. There is no boundary where perception stops and only then
cognition kicks in.

Textbooks still only show feed-forward arrows from occipital areas to
parietal/frontal.

#### Discrete concepts
Not "what is this?" -> (un pipe)

But: "what is this like?"

Bar, 2007, Trends in Cognitive Sciences:
When you see something new, it is connected to familiar concepts through
associations and use this to make predictions.

#### Top-down control of perception: spatial frequencies
In landmark study that found that FFA activity correlates with activity.
However OFC also activates durign succesful recognition.

Why?
1. Prerecognition -> it helps recognizing
2. Post-cognition -> succesful recognition?

Even when images are highly blurred, we can recognize objects, or at least
make a subset of objects that it could be.

Concept of spatial frequencies

Bar, Journal of Cognitive Neuroscience, 2003:
PFC helps in processing object recognition, by minimizing the set of
hypotheses.

To study two hypotheses (pre- versus post-recognition involvement of OFC),
MEG was used (Bar et al, PNAS, 2006).

Chaumon et al.: meaningful objects induce more OFC activation than Gabor
patches.

#### Context: objects in our enironment do not appear in isolation
Bar and Aminoff, Neuron, 2003:
Strong Context (hard hat, cow, bowling)
versus 
Weak Context (Camera, rubiks cube)

Environments help object recogniton. We have learned statistical
regularities about objects and their environment and we can apply this
knowledge in perception.

Behavioral result: lower RTs for object recogniton of pictures in
'congruent' environment

Idea: brain is "highly associative" ("like philosophers have said for years
now"). We are associatively predicting everyhting around us all the time.

Default mode network (DMN) is important argument in favor of this idea.

Associative processing and the generation of predictions are integral
processes of default activity in the proactive brain.

Memory is not a phot album, but rather a script book. We store scripts of
what happens to us. This guides our behavior in the future, based on real
as well as imagined experience.

We run simulations of our environment all day ("What if this giant lamp
here would fall down?!"). We can use this simulations later in real-life.

Is this why we are searching for novelties? (And marketeers put 'new, new,
new' on their products?)

### Conclusions
* Perception relies one xiting knowledge as much as it does on incoming
   information
* A rapid frst pass via anlogies?
* The prefrontal cortex might be involved in implementing all this

## Questions

#### What is your 'overarching definition of context?'
Bar: 3 ways
1. "If A and B come together..."
2. Semantic associations are harder... Interestingly, AI has also looked at
this..
3. Spatial context...

#### If we look at the contextual networks, in the medial areas. How do they interact with more lateral areas that interact with actions/the world?
A lot of processing/predictions happen internally: if you're in the kitchen
to make coffee, you know the structure of the kitchen and you don't have to
scan the entire kitchen for stuff you're not actually interested in.

#### We know that subcortical regions have a very fast representation of the visual scene. Can attention modulate this?
This has been looked into to little yet? Open question....

#  Tobias Donner - A New Face of Top-Down in Early Visual Cortex

## Neuronal coalitions and cortical dynamics
Cortical networks can be in stome minimal energy state (Hopfield).

Example: famous picture of face/two vases. Competitive dynamics of two
networks representing these two concepts.

## Neuromodulation
Important system that is ignored in this literature is the neuromodulation
systems:

1. Locus coeruleus NA system
2. Basal forebrain ACh system

Neuromodulation can happen at a very small time scale (order of seconds).

Donner: "Hypothesis I would like to put forward" -> Phasic neuromodulators
shape circuit interactions in visual cortex and, thus, perception.

"We would like to study this non-invasively in humans"

Two possible signatures of phasic neuromodulation:
1. Pupil dilation.
2. fMRI-signals (Logothesis (2006), already showde that BOLD isvery
   senstitive to neuromodulation. 

Phasic Neuromodulation-induced BOLD signal has been found in multiple fMRI
studies on perceptual decision-making in V1.

### De Gee, PNAS, 2014 - Pupil dilation reflects perceptual choice
Task:
Dynamic noise, sometimes an auditory cue is presented and the subject has
to indicate whether a noisy signal is or is not present.

Ress & Heeger, 2003 showed a V1 signal correlating with Hits/Misses/False
Alarms/Correct Rejections (higher singal in H and FAs). Standard
interpretation was that higher-order areas modulate with feedback signals.

de Gee et al show that pupil dilation (and thus phasic NM?) show a similar
pattern. Apparently, it is not prefrontal, but maybe
brainstem-neuromodulatory effect.

Using decision theory, some subjects could have been shown to be biased towards
rejecting the presence of a stimulus (they have more misses than false
alarms).

An unexpected finding, was that more conservative subjects show a strong
pupil choice effect, but liberal conservatives do not.

### Klooster et al. - Bistable Perception
Motion-induced blindness: focusing on center, peripheral stimulus
disappears due to moving cloud of crosses.

MEG study shows modulation of specific frequency bands (10-30 Hz). Less
activation in posterior parts of the brain when target disappears, more
activation frontal when target disappears.

When illusion is replayed, but no decision has to be made, this modulation
disappears. Apparently, the effect really coincides with the decision
process itself.

### What is the "top" in top-down?
There are two sources of top-down (in visual cortex):
1. Selective cortical feedback interactions (content-specific)
2. Phasic Neuromodulation

#### Hallmarks of phasic NMod:
1. Retionotopically widespread
2. Strong effects on cortical population signals (may even dominate
   top-down signals in fMRI)
3. Can shape perception by interacting with the cortical circuits that
   produce perceptual decisions.

#### effects of neuromodulation
1. Gain modulation
2. Altered Excitation/Inhbition balance
3. Dynamic network reconfiguration

#### Challenge
The fact that perception is altered by neuromodulators requires models for
understanding this.


## Questions
How do you know that pupil dilation reflects this particular part of
decision making?
Porably, the seed of the effects lies in higher order brain regions, not
the brainstem itself.


# Discussion Tobias Donner versus Bar
Chris Summerfield: Why Prefrontal Cortex? When people have Prefrontal
Cortex damage, they don't perceive differently?

Bar: that bothered us before, but we have an answer now.
OFC lights up in many, many tasks. You should look at the common
denominator. It seems as if this is actually simulating/predicting what
will happen.

How do these 1) neuromodulatory and 2) cortical feedback mechanism map back
onto the Bayesian inferencer model?  Tobias: it might be similar to the
exploration/exploitation mechanism in reinforcement learning. Where higher
neuromodulation/gain starts more exploratory ways of perception.  Bar: in
our model, we more think about it as 1) "initial gist" and 2) templates
that further prune and sophisticate this.


# Concluding discussion

## How do expectation and attention interrelate

## Is predictive coding neurophysiologically plausible?

## What is the 'top' in top-down perception?


### Discussion questions
Three questions:
1. Expectation is not a useful concept: it is attention in disguise.
2. Predictive coding has so many flavours and parameter that is has
   becoming unfalsifiable.
3. Grand unifying theories are less useful than focused specific theories
   to advance cognitive neuroscience.

Tobias
The kind of experiments we do rather speak to two different theories that
do very different predictions. With global theories this is harder to do.

Chris Summerfield
Let's assume that the free enegry principle is the best normative,
computational model what's "best to do". Even if that is true, we haven't
been able to build a model that can do more than find out if a youtube
video contains a cat or not.

Floris: Masha Bar, your data seems to speak in favor of predictive coding,
right?

Masha Bar: Maybe, but I'm not convinced that the predictive coding is the
final unifying theory. It is not specific enough.A

Floris: Karl Friston, you are the grand theorist...

Karl Friston: it helps connecting smaller theories. "Bayesian Inference is
just true... Big question is how it is implemented in the brain. Also, I
know of only 3 or 4 mathematical formulations of message passing that could
implement Bayesian inference.
I'm not interested in just describing behavior, it should fit in larger
theories.

Peter Kok: an argument in favor of unifying theory is that different
regions in the brain are very, very similar, as if a general mechanism is
at work.

Floris to Pieter Roelfsema: you have very specific stimuli in your
experiments. How well do your experiments generalize to more real
experiments?
Blalba.

Floris: the point of predictive coding is that you need generative models.
Do you have this also in V1?

Pieter Roelfsema: yes. We had an epileptic patient with electrode in V1. If
he imagines stuff in that retinotopic part, V1 retinotopic neurons spike.

Chris Summerfield: there are many (almost all) animals without a similar
cortex as us. However, they have pretty well-functioning visual systems.
This makes clear that homogeniety in cortex etc. are not strictly
necessary.

Marcus Bauer: it is not likely that all predictive coding takes place in
the canonical microcircuits in homogeneous cortex.
A lot of data does not speak in favor of vanilla predictive coding. It
could be that the components of attention and prediction are segegrated
after all. 

Chris Summerfield: we need a distinction between predicive coding/free
energy and hiearchically ordered sensory systems. Similar schemes exist in
the brain: e.g. reward prediction error signaled by dopamine, modulating
neural gain.

Floris de Lange: we need data that could falsify predictive coding, as
almost all data is compatible with predictive coding.

Pieter Roelfsema: my suscipicion is that only attended stimuli are
predicted.

Floris: example from 'on intelligence' of Jeff Hawkins: when somethign
changes about your door handle, you will notice when you open your door,
even when you're not attending consciously to the door.

Pieter Roelfsema: there is so much stuff going on, we cannot make
predictions about every single thing that's going on right now. We only
make predictions about stimuli that are relevant for the task at hand.

Karl Friston: simulations and theory are important. It actually shows that
the amount of information that falls on the retina is very limited. The
degrees of freedom what could happen are very small.
"I can't imagine running any simulation of Bayesian inference, without
making a very clear distinction between predicting things and attending to
things. This doesn't make sense."
I would like to demystify the mystery by an analogy: solving the source
localizaton problem with EEG. If you are dispensed with attention: you
regularize the covariance matrix using constraints.
